{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOumnr0jWxUDZ0hh6reCNkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhrubaAdhikary/GEN_AI_DEMO/blob/master/Conversational_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "F4EjYTax4zxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# 1. Define the Python function that the UI will call\n",
        "def handle_chat(user_input):\n",
        "    # This is where your LangGraph app logic goes\n",
        "    try:\n",
        "        # Simulate state for testing - replace with: state = app.invoke(...)\n",
        "        mock_response = f\"Simulated Response for: {user_input}\"\n",
        "        mock_intent = \"check_order\"\n",
        "\n",
        "        # This returns HTML to be appended to the chat log\n",
        "        return f\"\"\"\n",
        "        <div style=\"margin-bottom: 10px;\">\n",
        "          <b>User:</b> {user_input}<br>\n",
        "          <span style=\"color: teal;\"><b>NLU:</b> {mock_intent}</span><br>\n",
        "          <b>Agent:</b> {mock_response}\n",
        "          <hr>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    except Exception as e:\n",
        "        return f\"<div style='color:red'>Error: {str(e)}</div>\"\n",
        "\n",
        "# Register the function so JavaScript can see it\n",
        "google.colab.output.register_callback('notebook.handle_chat', handle_chat)\n",
        "\n",
        "# 2. Build the HTML/JS Interface\n",
        "chat_ui = \"\"\"\n",
        "<div id=\"chat-container\" style=\"font-family: sans-serif; border: 1px solid #ccc; padding: 15px; border-radius: 8px; background: #f9f9f9;\">\n",
        "    <div id=\"log\" style=\"height: 200px; overflow-y: auto; background: white; border: 1px solid #ddd; padding: 10px; margin-bottom: 10px;\">\n",
        "        <i>Chat history will appear here...</i>\n",
        "    </div>\n",
        "    <input type=\"text\" id=\"user-input\" style=\"width: 70%; padding: 5px;\" placeholder=\"Ask about your order...\">\n",
        "    <button onclick=\"sendToPython()\" style=\"padding: 5px 15px; cursor: pointer; background: #28a745; color: white; border: none; border-radius: 4px;\">Send</button>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "async function sendToPython() {\n",
        "    const input = document.getElementById('user-input');\n",
        "    const log = document.getElementById('log');\n",
        "    const text = input.value;\n",
        "    if (!text) return;\n",
        "\n",
        "    input.value = ''; // Clear input\n",
        "\n",
        "    // Call the Python function we registered\n",
        "    const result = await google.colab.kernel.invokeFunction('notebook.handle_chat', [text], {});\n",
        "\n",
        "    // Append the result to our chat log\n",
        "    log.innerHTML += result.data['text/plain'];\n",
        "    log.scrollTop = log.scrollHeight; // Auto-scroll\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(chat_ui))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "hD8GQdTT5pq_",
        "outputId": "3b9ce3d7-1c5a-4603-d311-f66bd9b06e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div id=\"chat-container\" style=\"font-family: sans-serif; border: 1px solid #ccc; padding: 15px; border-radius: 8px; background: #f9f9f9;\">\n",
              "    <div id=\"log\" style=\"height: 200px; overflow-y: auto; background: white; border: 1px solid #ddd; padding: 10px; margin-bottom: 10px;\">\n",
              "        <i>Chat history will appear here...</i>\n",
              "    </div>\n",
              "    <input type=\"text\" id=\"user-input\" style=\"width: 70%; padding: 5px;\" placeholder=\"Ask about your order...\">\n",
              "    <button onclick=\"sendToPython()\" style=\"padding: 5px 15px; cursor: pointer; background: #28a745; color: white; border: none; border-radius: 4px;\">Send</button>\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "async function sendToPython() {\n",
              "    const input = document.getElementById('user-input');\n",
              "    const log = document.getElementById('log');\n",
              "    const text = input.value;\n",
              "    if (!text) return;\n",
              "\n",
              "    input.value = ''; // Clear input\n",
              "    \n",
              "    // Call the Python function we registered\n",
              "    const result = await google.colab.kernel.invokeFunction('notebook.handle_chat', [text], {});\n",
              "    \n",
              "    // Append the result to our chat log\n",
              "    log.innerHTML += result.data['text/plain'];\n",
              "    log.scrollTop = log.scrollHeight; // Auto-scroll\n",
              "}\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh3Mv-f9veCX"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langgraph langchain_openai ipywidgets nltk\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Order-Status-Orchestrator\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import operator\n",
        "# from typing import Annotated, List, TypedDict, Union\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "# from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# # 1. State Definition\n",
        "# class AgentState(TypedDict):\n",
        "#     messages: Annotated[List[BaseMessage], operator.add]\n",
        "#     order_id: Union[str, None]\n",
        "#     sentiment: str\n",
        "#     intent: str\n",
        "\n",
        "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# # 2. NLU Node: Extracts Intent, Sentiment, and Entities (Order ID)\n",
        "# def nlu_node(state: AgentState):\n",
        "#     last_message = state[\"messages\"][-1].content\n",
        "#     # Few-Shot instruction for NLU\n",
        "#     prompt = f\"\"\"Analyze the user input: \"{last_message}\"\n",
        "#     Extract:\n",
        "#     - Intent (e.g., check_order, greeting)\n",
        "#     - Sentiment (Positive, Negative, Neutral)\n",
        "#     - Order ID (if mentioned, otherwise None)\n",
        "#     Return as: Intent | Sentiment | OrderID\"\"\"\n",
        "\n",
        "#     res = llm.invoke(prompt).content.split(\" | \")\n",
        "#     return {\n",
        "#         \"intent\": res[0],\n",
        "#         \"sentiment\": res[1],\n",
        "#         \"order_id\": res[2] if \"None\" not in res[2] else None\n",
        "#     }\n",
        "\n",
        "# # 3. Dialogue Manager logic (The Router)\n",
        "# def dialogue_manager_router(state: AgentState):\n",
        "#     if state[\"order_id\"] is None:\n",
        "#         return \"ask_for_id\"\n",
        "#     return \"retrieve_order\"\n",
        "\n",
        "# # 4. Clarification Node (Missing Entity)\n",
        "# def ask_for_id_node(state: AgentState):\n",
        "#     return {\"messages\": [AIMessage(content=\"I can help with that! What is your order number?\")]}\n",
        "\n",
        "# # 5. RAG Retriever Node (Context & Prompt)\n",
        "# def retrieve_order_node(state: AgentState):\n",
        "#     # Simulated Database Lookup based on 'Order Database' in image\n",
        "#     order_info = f\"Order {state['order_id']} has shipped and will arrive tomorrow.\"\n",
        "#     return {\"messages\": [AIMessage(content=order_info)]}\n",
        "\n",
        "# # --- Build the Graph ---\n",
        "# workflow = StateGraph(AgentState)\n",
        "# workflow.add_node(\"nlu\", nlu_node)\n",
        "# workflow.add_node(\"ask_for_id\", ask_for_id_node)\n",
        "# workflow.add_node(\"retrieve_order\", retrieve_order_node)\n",
        "\n",
        "# workflow.add_edge(START, \"nlu\")\n",
        "# workflow.add_conditional_edges(\"nlu\", dialogue_manager_router)\n",
        "# workflow.add_edge(\"ask_for_id\", END)\n",
        "# workflow.add_edge(\"retrieve_order\", END)\n",
        "\n",
        "# app = workflow.compile()\n",
        "\n"
      ],
      "metadata": {
        "id": "zURnXg5d5Bkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import operator\n",
        "import google.colab.output\n",
        "from typing import Annotated, List, TypedDict, Union\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# 1. DISABLE LANGSMITH TRACING (Removes the 401 Warnings)\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGSMITH_KEY')\n",
        "\n",
        "# 2. Define the Python function that the UI will call\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# --- Graph Logic with Robust Parsing ---\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    order_id: Union[str, None]\n",
        "    sentiment: str\n",
        "    intent: str\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "def nlu_node(state: AgentState):\n",
        "    last_message = state[\"messages\"][-1].content\n",
        "    prompt = f\"\"\"Analyze: \"{last_message}\"\n",
        "    Return ONLY: Intent | Sentiment | OrderID (use None if missing)\"\"\"\n",
        "\n",
        "    try:\n",
        "        res_raw = llm.invoke(prompt).content\n",
        "        # Split and clean whitespace\n",
        "        parts = [p.strip() for p in res_raw.split(\"|\")]\n",
        "\n",
        "        # Defensive check: ensure list has at least 3 items\n",
        "        intent = parts[0] if len(parts) > 0 else \"unknown\"\n",
        "        sentiment = parts[1] if len(parts) > 1 else \"Neutral\"\n",
        "        oid = parts[2] if len(parts) > 2 else \"None\"\n",
        "\n",
        "        return {\n",
        "            \"intent\": intent,\n",
        "            \"sentiment\": sentiment,\n",
        "            \"order_id\": oid if \"None\" not in oid else None\n",
        "        }\n",
        "    except Exception:\n",
        "        return {\"intent\": \"error\", \"sentiment\": \"Neutral\", \"order_id\": None}\n",
        "\n",
        "# ... (rest of your nodes: ask_for_id_node, retrieve_order_node, and dialogue_manager_router remain the same) ...\n",
        "\n",
        "def dialogue_manager_router(state: AgentState):\n",
        "    return \"ask_for_id\" if state[\"order_id\"] is None else \"retrieve_order\"\n",
        "\n",
        "def ask_for_id_node(state: AgentState):\n",
        "    return {\"messages\": [AIMessage(content=\"I can help with that! What is your order number?\")]}\n",
        "\n",
        "def retrieve_order_node(state: AgentState):\n",
        "    order_info = f\"Order {state['order_id']} has shipped and will arrive tomorrow.\"\n",
        "    return {\"messages\": [AIMessage(content=order_info)]}\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"nlu\", nlu_node)\n",
        "workflow.add_node(\"ask_for_id\", ask_for_id_node)\n",
        "workflow.add_node(\"retrieve_order\", retrieve_order_node)\n",
        "workflow.add_edge(START, \"nlu\")\n",
        "workflow.add_conditional_edges(\"nlu\", dialogue_manager_router)\n",
        "workflow.add_edge(\"ask_for_id\", END)\n",
        "workflow.add_edge(\"retrieve_order\", END)\n",
        "app = workflow.compile()\n",
        "\n",
        "# --- The UI Bridge ---\n",
        "def handle_chat(user_input):\n",
        "    try:\n",
        "        state = app.invoke({\"messages\": [HumanMessage(content=user_input)], \"order_id\": None})\n",
        "        response = state[\"messages\"][-1].content\n",
        "        return f\"<div><b>User:</b> {user_input}<br><small>NLU: {state['intent']}</small><br><b>Agent:</b> {response}<hr></div>\"\n",
        "    except Exception as e:\n",
        "        return f\"<div style='color:red'>Error: {str(e)}</div>\"\n",
        "\n",
        "google.colab.output.register_callback('notebook.handle_chat', handle_chat)\n",
        "display(HTML(chat_html)) # Uses the same chat_html from our previous step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "sjalfVWn5Pjc",
        "outputId": "b17dd1f7-4a1d-479e-d406-45b9e3bdfbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div id=\"wrapper\" style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; max-width: 600px; border: 1px solid #ddd; border-radius: 8px; overflow: hidden;\">\n",
              "    <div style=\"background: #007bff; color: white; padding: 10px 15px; font-weight: bold;\">Order Support Agent (LangGraph)</div>\n",
              "    <div id=\"chat-log\" style=\"height: 300px; overflow-y: auto; padding: 15px; background: white;\">\n",
              "        <i style=\"color: #999;\">Type 'Where is my order #123' or just 'Hi' to start...</i>\n",
              "    </div>\n",
              "    <div style=\"display: flex; border-top: 1px solid #ddd; padding: 10px; background: #f8f9fa;\">\n",
              "        <input type=\"text\" id=\"chat-input\" style=\"flex-grow: 1; padding: 8px; border: 1px solid #ccc; border-radius: 4px;\" placeholder=\"Message...\">\n",
              "        <button onclick=\"sendMessage()\" style=\"margin-left: 10px; padding: 8px 20px; background: #28a745; color: white; border: none; border-radius: 4px; cursor: pointer;\">Send</button>\n",
              "    </div>\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "async function sendMessage() {\n",
              "    const input = document.getElementById('chat-input');\n",
              "    const log = document.getElementById('chat-log');\n",
              "    const val = input.value;\n",
              "    if (!val) return;\n",
              "\n",
              "    input.value = 'Thinking...';\n",
              "    input.disabled = true;\n",
              "\n",
              "    const result = await google.colab.kernel.invokeFunction('notebook.handle_chat', [val], {});\n",
              "    \n",
              "    if (log.innerHTML.includes('<i>')) log.innerHTML = ''; // Clear placeholder\n",
              "    log.innerHTML += result.data['text/plain'];\n",
              "    log.scrollTop = log.scrollHeight;\n",
              "    \n",
              "    input.value = '';\n",
              "    input.disabled = false;\n",
              "    input.focus();\n",
              "}\n",
              "// Allow 'Enter' key to send\n",
              "document.getElementById('chat-input').addEventListener('keypress', function (e) {\n",
              "    if (e.key === 'Enter') sendMessage();\n",
              "});\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=019c37ec-69c0-7ee0-a50d-5988d68f48fe,id=019c37ec-69c0-7ee0-a50d-5988d68f48fe; trace=019c37ec-69c0-7ee0-a50d-5988d68f48fe,id=019c37ec-69d4-7ba2-a6e6-99d1dad393d3; trace=019c37ec-69c0-7ee0-a50d-5988d68f48fe,id=019c37ec-69d5-72c1-ad52-741d9050a6b2\n",
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=019c37ec-9979-7170-bb73-d2e8086a9c08,id=019c37ec-9979-7170-bb73-d2e8086a9c08; trace=019c37ec-9979-7170-bb73-d2e8086a9c08,id=019c37ec-997d-7262-b952-d9b76c2a82fe; trace=019c37ec-9979-7170-bb73-d2e8086a9c08,id=019c37ec-997f-7631-bba5-3ff7a356e411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPV8Ag7S5cao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}